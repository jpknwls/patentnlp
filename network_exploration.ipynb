{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patent_data = np.load('../data/patent_tiny.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "links = set()\n",
    "\n",
    "for data in patent_data:\n",
    "    for word in data['content']:\n",
    "        vocab.add(word)\n",
    "    for link in data['citations']:\n",
    "        links.add(link)\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}\n",
    "link_to_ix = {link: i for i, link in enumerate(links)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99615\n",
      "48129\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))\n",
    "print(len(links))\n",
    "#print(patent_data[100]['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3526\n"
     ]
    }
   ],
   "source": [
    "def generate_training_data(data, links_dict):\n",
    "    t_data = []\n",
    "    _data = [(d['content'],d['citations']) for d in data]\n",
    "    for d in _data:\n",
    "        one_hot = np.zeros(len(links_dict), dtype=np.int_)\n",
    "        for a in d[1]: one_hot[link_to_ix[a]] = 1\n",
    "        t_data.append((d[0], one_hot))\n",
    "    return t_data\n",
    "d = generate_training_data(patent_data, links)\n",
    "print(len(d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.hidden = nn.Linear(embedding_dim + hidden_size, hidden_size)\n",
    "        self.output = nn.Linear(embedding_dim + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embeds = self.embeddings(input).view((1, -1))\n",
    "        combined = torch.cat((embeds, hidden), 1)\n",
    "        hidden = self.hidden(combined)\n",
    "        output = self.output(combined)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, n_hidden)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, hidden_size, output_size, vocab_size, embedding_dim):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "    def forward(self, input): return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fc network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(FC, self).__init__()\n",
    "        self.first = nn.Linear(input_size,2*hidden_size)\n",
    "        self.second = nn.Linear(2*hidden_size,hidden_size)\n",
    "        self.third = nn.Linear(hidden_size,output_size)\n",
    "\n",
    "    def forward(self, features):\n",
    "        _first = self.first(features)\n",
    "        _second = self.second(_first)\n",
    "        output = self.third(_second)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## classification network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classify(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Classify, self).__init__()\n",
    "        self.softmax =  nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, representation):\n",
    "        return self.softmax(representation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss\n",
    "### cross-entropy loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_loss = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multi-label margin loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_loss = torch.nn.MultiLabelMarginLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bce with logits loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "bce_loss = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric\n",
    "### mean average precision implementation\n",
    "https://github.com/joaopalotti/trec_tools/blob/master/trectools/trec_eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMAP(self, depth=1000, per_query=False, trec_eval=True):\n",
    "        label = \"MAP@%ddepth\" % (depth)\n",
    "\n",
    "        # We only care for binary evaluation here:\n",
    "        relevant_docs = self.qrels.qrels_data[self.qrels.qrels_data.rel > 0].copy()\n",
    "        relevant_docs[\"rel\"] = 1\n",
    "\n",
    "        if trec_eval:\n",
    "            trecformat = self.run.run_data.sort_values([\"query\", \"score\", \"docid\"], ascending=[True,False,False]).reset_index()\n",
    "            topX = trecformat.groupby(\"query\")[[\"query\",\"docid\",\"score\"]].head(depth)\n",
    "        else:\n",
    "            topX = self.run.run_data.groupby(\"query\")[[\"query\",\"docid\",\"score\"]].head(depth)\n",
    "\n",
    "        # check number of queries\n",
    "        nqueries = len(self.run.topics())\n",
    "\n",
    "        # Make sure that rank position starts by 1\n",
    "        topX[\"rank\"] = 1\n",
    "        topX[\"rank\"] = topX.groupby(\"query\")[\"rank\"].cumsum()\n",
    "        topX[\"discount\"] = 1. / np.log2(topX[\"rank\"]+1)\n",
    "\n",
    "        # Keep only documents that are relevant (rel > 0)\n",
    "        selection = pd.merge(topX, relevant_docs[[\"query\",\"docid\",\"rel\"]], how=\"left\")\n",
    "\n",
    "        selection[\"rel\"] = selection.groupby(\"query\")[\"rel\"].cumsum()\n",
    "        # contribution of each relevant document\n",
    "        selection[label] = selection[\"rel\"] / selection[\"rank\"]\n",
    "\n",
    "        # MAP is the sum of individual's contribution\n",
    "        map_per_query = selection[[\"query\", label]].groupby(\"query\").sum()\n",
    "        relevant_docs[label] = relevant_docs[\"rel\"]\n",
    "        nrel_per_query = relevant_docs[[\"query\",label]].groupby(\"query\").sum()\n",
    "        map_per_query = map_per_query / nrel_per_query\n",
    "\n",
    "        if per_query:\n",
    "            \"\"\" This will return a pandas dataframe with [\"query\", \"NDCG\"] values \"\"\"\n",
    "            return map_per_query\n",
    "\n",
    "        if map_per_query.empty:\n",
    "            return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _map():return\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, f_e, f_c, classify, loss, idx, device):\n",
    "        super(Network, self).__init__()\n",
    "        self.device = device\n",
    "        self.f_e = f_e\n",
    "        self.f_c = f_c\n",
    "        self.classify = classify\n",
    "        self.loss = loss\n",
    "        self.word_idx = idx\n",
    "        \n",
    "    def forward(self, input, target):\n",
    "        # feature extraction\n",
    "        _hidden = self.f_e.init_hidden()\n",
    "        for word in input:\n",
    "            _input = torch.tensor([self.word_idx[word]], dtype=torch.long)\n",
    "            hidden = self.f_e(_input, _hidden)\n",
    "            _hidden = hidden[1]\n",
    "        features = hidden[0]\n",
    "        #print('FEATURES:',features)\n",
    "\n",
    "        # feature aggregation\n",
    "        representation = self.f_c(features)\n",
    "        #print('REP:', representation)\n",
    "\n",
    "        # prediction\n",
    "        prediction = self.classify(representation)\n",
    "        #print('PREDICTION:', prediction.shape)\n",
    "    \n",
    "        target = torch.tensor(target).unsqueeze(0).to(device=device, dtype=torch.int64)\n",
    "        #print('TARGET', target.shape)\n",
    "        #loss\n",
    "        return self.loss(prediction, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "_lr = .0001\n",
    "cuda = False\n",
    "n_hidden = 128\n",
    "embedding_dim = 100\n",
    "output_size = len(links)\n",
    "fc_hidden = 512\n",
    "rnn = RNN(n_hidden, embedding_dim, len(vocab), embedding_dim)\n",
    "fc = FC(embedding_dim, fc_hidden, output_size)\n",
    "classify = Classify() \n",
    "device = torch.device(\"cuda:0\" if cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network(rnn, fc, classify, mlm_loss, word_to_ix, device)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=_lr)#fill in params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "step = 0\n",
    "for _d in d:\n",
    "    step += 1\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    loss = net.forward(_d[0], _d[1])\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    grad_norm = torch.nn.utils.clip_grad_norm_(net.parameters(), 5.0)\n",
    "\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
